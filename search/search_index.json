{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"LLAISYS\uff08Let's Learn AI SYStem\uff09","text":"<p>\u672c\u9879\u76ee\u6e90\u81ea \u542f\u5143\u4eba\u5de5\u667a\u80fd\u8bad\u7ec3\u8425 \u00b7 \u5927\u6a21\u578b\u63a8\u7406\u6846\u67b6\u65b9\u5411 \u7684\u8bfe\u7a0b\u4f5c\u4e1a\uff0c\u65e8\u5728\u5e2e\u52a9\u521d\u5b66\u8005\u4ece\u96f6\u6784\u5efa\u5927\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u3002\u5f53\u524d\u7248\u672c\u5df2\u5b9e\u73b0\u57fa\u7840\u529f\u80fd\uff0c\u5e76\u4f5c\u4e3a\u65b0\u63a8\u7406\u6846\u67b6 zedinfer \u7684\u8bd5\u9a8c\u5e73\u53f0\uff0c\u4e3b\u8981\u7528\u4e8e\uff1a</p> <ul> <li>\u9a8c\u8bc1\u81ea\u5b9a\u4e49\u7b97\u5b50\u5b9e\u73b0\u7684\u6b63\u786e\u6027\uff08\u4e0e Hugging Face \u63a8\u7406\u7ed3\u679c\u5bf9\u9f50\uff09  </li> <li>\u8bc4\u4f30\u81ea\u5b9a\u4e49\u7b97\u5b50\u7684\u6027\u80fd</li> </ul> <p>\ud83d\udccc \u6ce8\u610f\uff1a\u672c\u9879\u76ee\u4e0d\u518d\u65b0\u589e\u529f\u80fd\uff0c\u4ec5\u7528\u4e8e\u7b97\u5b50\u5f00\u53d1\u4e0e\u6027\u80fd\u6d4b\u8bd5\u3002</p>"},{"location":"#_1","title":"\u2705 \u5f53\u524d\u5b9e\u73b0","text":"<ul> <li>\u6a21\u578b\u652f\u6301\uff1aQwen2 \u6a21\u578b\u5728 CPU \u4e0a\u7684\u5b8c\u6574\u63a8\u7406\u6d41\u7a0b\uff08\u542b KV Cache\uff09</li> <li>\u7b97\u5b50\u4f18\u5316\uff1a<ul> <li>\u4f7f\u7528 AVX \u6307\u4ee4\u96c6 \u52a0\u901f\u6838\u5fc3\u8ba1\u7b97</li> <li>\u901a\u8fc7 OpenMP \u5b9e\u73b0\u591a\u7ebf\u7a0b\u5e76\u884c</li> <li>\u9ad8\u6548\u6570\u636e\u7c7b\u578b\u8f6c\u6362\uff1a<ul> <li><code>f16 &lt;=&gt; f32</code>\uff1a\u5229\u7528 F16C \u6307\u4ee4</li> <li><code>bf16 &lt;=&gt; f32</code>\uff1a\u5229\u7528 AVX \u6307\u4ee4</li> </ul> </li> </ul> </li> </ul>"},{"location":"#_2","title":"\ud83d\ude80 \u5feb\u901f\u5f00\u59cb","text":""},{"location":"#_3","title":"\u7f16\u8bd1\u4e0e\u5b89\u88c5","text":"Bash<pre><code># \u7f16\u8bd1 C++ \u540e\u7aef\nxmake\n\n# \u5b89\u88c5\u5171\u4eab\u5e93\nxmake install\n\n# \u5b89\u88c5 Python \u524d\u7aef\u5305\npip install ./python/\n</code></pre>"},{"location":"#_4","title":"\u7b97\u5b50\u6d4b\u8bd5","text":"<p>\u4ee5 <code>add</code> \u7b97\u5b50\u4e3a\u4f8b\u3002</p> Bash<pre><code># \u6b63\u786e\u6027\u6d4b\u8bd5\uff08CPU\uff09\npython test/ops/add.py\n\n# \u6b63\u786e\u6027\u6d4b\u8bd5\uff08NVIDIA GPU\uff09\npython test/ops/add.py --nvidia\n\n# \u6027\u80fd\u5206\u6790\uff08CPU\uff09\npython test/ops/add.py --profile\n\n# \u6027\u80fd\u5206\u6790\uff08NVIDIA GPU\uff09\npython test/ops/add.py --nvidia --profile\n</code></pre>"},{"location":"#_5","title":"\u63a8\u7406\u9a8c\u8bc1","text":"Bash<pre><code>python test/test_infer.py --model /path/to/qwen2/model --test\n</code></pre> <p>\ud83d\udd0d \u542f\u7528 <code>--test</code> \u9009\u9879\u5c06\u5173\u95ed Top-p\u3001Top-k \u548c Temperature \u91c7\u6837\uff0c\u5f3a\u5236 Hugging Face \u4f7f\u7528 ArgMax\uff08\u8d2a\u5a6a\u91c7\u6837\uff09\uff0c\u786e\u4fdd\u4e0e\u672c\u63a8\u7406\u5f15\u64ce\u7684\u91c7\u6837\u7ed3\u679c\u4e25\u683c\u4e00\u81f4\uff0c\u4fbf\u4e8e\u8c03\u8bd5\u4e0e\u9a8c\u8bc1\u3002</p>"},{"location":"#_6","title":"\ud83d\udd1c \u540e\u7eed\u5de5\u4f5c\uff08\u8bd5\u9a8c\u65b9\u5411\uff09","text":"<ol> <li>\u7b97\u5b50\u4f18\u5316\u4e0e\u6269\u5c55<ul> <li>\u8fdb\u4e00\u6b65\u4f18\u5316\u73b0\u6709\u7b97\u5b50\u6027\u80fd</li> <li>\u5b9e\u73b0\u65b0\u7b97\u5b50\uff08\u5982 LayerNorm\u3001Softmax \u7b49\uff09</li> </ul> </li> <li>\u91cf\u5316\u652f\u6301<ul> <li>\u5f00\u53d1 INT4/INT8/FP8 \u91cf\u5316\u7b97\u5b50</li> <li>\u652f\u6301\u7aef\u4fa7\u9ad8\u6548\u63a8\u7406</li> </ul> </li> </ol>"},{"location":"#_7","title":"\ud83d\udcda \u76f8\u5173\u8d44\u6e90","text":"<ul> <li>\u8bad\u7ec3\u8425\u8bfe\u7a0b\uff1a\u5927\u6a21\u578b\u63a8\u7406\u4e0e\u670d\u52a1\u7cfb\u7edf</li> <li>\u8bfe\u7a0b\u9879\u76ee\u4ed3\u5e93\uff1aInfiniTensor/llaisys</li> </ul>"},{"location":"ops/cpu/","title":"CPU \u7b97\u5b50\u6027\u80fd\u6d4b\u8bc4","text":""},{"location":"ops/cpu/#add","title":"Add","text":"Bash<pre><code>Testing Ops.add on cpu\n   shape (1, 1536) dtype &lt;f32&gt;\n        Torch time: 0.00262 ms\n        LLAISYS time: 0.00125 ms\n   shape (1, 1536) dtype &lt;f16&gt;\n        Torch time: 0.00374 ms\n        LLAISYS time: 0.00221 ms\n   shape (1, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.00395 ms\n        LLAISYS time: 0.00249 ms\n   shape (128, 1536) dtype &lt;f32&gt;\n        Torch time: 0.02013 ms\n        LLAISYS time: 0.01101 ms\n   shape (128, 1536) dtype &lt;f16&gt;\n        Torch time: 0.02257 ms\n        LLAISYS time: 0.00874 ms\n   shape (128, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.02727 ms\n        LLAISYS time: 0.01166 ms\n   shape (1, 4096) dtype &lt;f32&gt;\n        Torch time: 0.00378 ms\n        LLAISYS time: 0.00219 ms\n   shape (1, 4096) dtype &lt;f16&gt;\n        Torch time: 0.00390 ms\n        LLAISYS time: 0.00284 ms\n   shape (1, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.00320 ms\n        LLAISYS time: 0.00145 ms\n   shape (512, 4096) dtype &lt;f32&gt;\n        Torch time: 0.11454 ms\n        LLAISYS time: 0.11411 ms\n   shape (512, 4096) dtype &lt;f16&gt;\n        Torch time: 0.05422 ms\n        LLAISYS time: 0.02505 ms\n   shape (512, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.06755 ms\n        LLAISYS time: 0.02741 ms\n   shape (1, 5120) dtype &lt;f32&gt;\n        Torch time: 0.00294 ms\n        LLAISYS time: 0.00197 ms\n   shape (1, 5120) dtype &lt;f16&gt;\n        Torch time: 0.00324 ms\n        LLAISYS time: 0.00160 ms\n   shape (1, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.00350 ms\n        LLAISYS time: 0.00158 ms\n   shape (1024, 5120) dtype &lt;f32&gt;\n        Torch time: 0.40985 ms\n        LLAISYS time: 0.36958 ms\n   shape (1024, 5120) dtype &lt;f16&gt;\n        Torch time: 0.12914 ms\n        LLAISYS time: 0.11051 ms\n   shape (1024, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.15628 ms\n        LLAISYS time: 0.10541 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#argmax","title":"Argmax","text":"Bash<pre><code>Testing Ops.argmax on cpu\n   shape (151936,) dtype &lt;f32&gt;\n        Torch time: 0.18724 ms\n        LLAISYS time: 0.02910 ms\n   shape (151936,) dtype &lt;f16&gt;\n        Torch time: 0.24002 ms\n        LLAISYS time: 0.03584 ms\n   shape (151936,) dtype &lt;bf16&gt;\n        Torch time: 0.18334 ms\n        LLAISYS time: 0.03125 ms\n   shape (152064,) dtype &lt;f32&gt;\n        Torch time: 0.17431 ms\n        LLAISYS time: 0.02723 ms\n   shape (152064,) dtype &lt;f16&gt;\n        Torch time: 0.23121 ms\n        LLAISYS time: 0.03022 ms\n   shape (152064,) dtype &lt;bf16&gt;\n        Torch time: 0.17427 ms\n        LLAISYS time: 0.03281 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#embedding","title":"Embedding","text":"Bash<pre><code>Testing Ops.embedding on cpu\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;f32&gt;\n        Torch time: 0.01091 ms\n        LLAISYS time: 0.00142 ms\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;f16&gt;\n        Torch time: 0.01069 ms\n        LLAISYS time: 0.00138 ms\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.01073 ms\n        LLAISYS time: 0.00139 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;f32&gt;\n        Torch time: 0.04728 ms\n        LLAISYS time: 0.00686 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;f16&gt;\n        Torch time: 0.06468 ms\n        LLAISYS time: 0.00584 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.06009 ms\n        LLAISYS time: 0.00586 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;f32&gt;\n        Torch time: 0.02345 ms\n        LLAISYS time: 0.00228 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;f16&gt;\n        Torch time: 0.02479 ms\n        LLAISYS time: 0.00220 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.02001 ms\n        LLAISYS time: 0.00211 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;f32&gt;\n        Torch time: 0.25836 ms\n        LLAISYS time: 0.04098 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;f16&gt;\n        Torch time: 0.17668 ms\n        LLAISYS time: 0.01430 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.19080 ms\n        LLAISYS time: 0.01505 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;f32&gt;\n        Torch time: 0.02132 ms\n        LLAISYS time: 0.00256 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;f16&gt;\n        Torch time: 0.02654 ms\n        LLAISYS time: 0.00209 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.39996 ms\n        LLAISYS time: 0.00208 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;f32&gt;\n        Torch time: 0.82579 ms\n        LLAISYS time: 0.27305 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;f16&gt;\n        Torch time: 0.50608 ms\n        LLAISYS time: 0.08731 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.50539 ms\n        LLAISYS time: 0.08463 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#linear","title":"Linear","text":"Bash<pre><code>Testing Ops.linear on cpu\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.03361 ms\n        LLAISYS time: 0.01900 ms\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.06082 ms\n        LLAISYS time: 1.57289 ms\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.04559 ms\n        LLAISYS time: 1.56664 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.29750 ms\n        LLAISYS time: 0.28915 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.21772 ms\n        LLAISYS time: 34.62622 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.19600 ms\n        LLAISYS time: 36.17344 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;f32&gt;\n        Torch time: 0.28882 ms\n        LLAISYS time: 0.28607 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;f16&gt;\n        Torch time: 0.22915 ms\n        LLAISYS time: 34.99666 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.17964 ms\n        LLAISYS time: 33.93682 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.56798 ms\n        LLAISYS time: 0.78859 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 3.84477 ms\n        LLAISYS time: 2.64170 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 2.34522 ms\n        LLAISYS time: 2.54400 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 3.07649 ms\n        LLAISYS time: 4.30245 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 23.59190 ms\n        LLAISYS time: 42.73773 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 15.30035 ms\n        LLAISYS time: 45.11836 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;f32&gt;\n        Torch time: 3.09185 ms\n        LLAISYS time: 3.80646 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;f16&gt;\n        Torch time: 24.33968 ms\n        LLAISYS time: 48.82042 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;bf16&gt;\n        Torch time: 15.37450 ms\n        LLAISYS time: 45.82588 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 4.96520 ms\n        LLAISYS time: 0.48969 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 0.22523 ms\n        LLAISYS time: 45.14448 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.21774 ms\n        LLAISYS time: 44.73020 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 2.83935 ms\n        LLAISYS time: 3.07710 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 1.23924 ms\n        LLAISYS time: 137.01032 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 1.22400 ms\n        LLAISYS time: 136.92062 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;f32&gt;\n        Torch time: 4.28824 ms\n        LLAISYS time: 11.54811 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;f16&gt;\n        Torch time: 0.97658 ms\n        LLAISYS time: 130.72597 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;bf16&gt;\n        Torch time: 1.32715 ms\n        LLAISYS time: 129.38635 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 14.25879 ms\n        LLAISYS time: 14.06091 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 108.16152 ms\n        LLAISYS time: 63.04230 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 56.59506 ms\n        LLAISYS time: 64.24726 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 61.88507 ms\n        LLAISYS time: 47.41931 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 343.00961 ms\n        LLAISYS time: 211.98854 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 174.88398 ms\n        LLAISYS time: 182.13484 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;f32&gt;\n        Torch time: 39.11919 ms\n        LLAISYS time: 41.88408 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;f16&gt;\n        Torch time: 309.32579 ms\n        LLAISYS time: 212.45988 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;bf16&gt;\n        Torch time: 193.40550 ms\n        LLAISYS time: 222.96064 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 0.98204 ms\n        LLAISYS time: 0.84421 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 0.40913 ms\n        LLAISYS time: 68.30993 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.38231 ms\n        LLAISYS time: 67.38297 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 7.78060 ms\n        LLAISYS time: 7.25434 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 3.11443 ms\n        LLAISYS time: 359.53287 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 5.79628 ms\n        LLAISYS time: 366.67006 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;f32&gt;\n        Torch time: 5.26121 ms\n        LLAISYS time: 5.34323 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;f16&gt;\n        Torch time: 2.87167 ms\n        LLAISYS time: 369.14826 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;bf16&gt;\n        Torch time: 2.97650 ms\n        LLAISYS time: 358.56265 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 45.56138 ms\n        LLAISYS time: 51.91351 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 375.08587 ms\n        LLAISYS time: 155.66170 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 174.48737 ms\n        LLAISYS time: 123.31779 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 216.18288 ms\n        LLAISYS time: 265.72510 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 1675.24603 ms\n        LLAISYS time: 661.32040 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 928.39165 ms\n        LLAISYS time: 667.72926 ms\n</code></pre>"},{"location":"ops/cpu/#rms-norm","title":"RMS Norm","text":"Bash<pre><code>Testing Ops.rms_norm on cpu\n   shape (1, 1536) dtype &lt;f32&gt;\n        Torch time: 0.03278 ms\n        LLAISYS time: 0.00974 ms\n   shape (1, 1536) dtype &lt;f16&gt;\n        Torch time: 0.04348 ms\n        LLAISYS time: 0.00918 ms\n   shape (1, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.04075 ms\n        LLAISYS time: 0.00936 ms\n   shape (128, 1536) dtype &lt;f32&gt;\n        Torch time: 0.10410 ms\n        LLAISYS time: 0.01235 ms\n   shape (128, 1536) dtype &lt;f16&gt;\n        Torch time: 0.26267 ms\n        LLAISYS time: 0.02107 ms\n   shape (128, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.13555 ms\n        LLAISYS time: 0.01920 ms\n   shape (1, 4096) dtype &lt;f32&gt;\n        Torch time: 0.03412 ms\n        LLAISYS time: 0.00970 ms\n   shape (1, 4096) dtype &lt;f16&gt;\n        Torch time: 0.05613 ms\n        LLAISYS time: 0.01235 ms\n   shape (1, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.04360 ms\n        LLAISYS time: 0.01194 ms\n   shape (512, 4096) dtype &lt;f32&gt;\n        Torch time: 0.30095 ms\n        LLAISYS time: 0.06323 ms\n   shape (512, 4096) dtype &lt;f16&gt;\n        Torch time: 0.80285 ms\n        LLAISYS time: 0.16998 ms\n   shape (512, 4096) dtype &lt;bf16&gt;\n        Torch time: 1.03045 ms\n        LLAISYS time: 0.17510 ms\n   shape (1, 5120) dtype &lt;f32&gt;\n        Torch time: 0.03440 ms\n        LLAISYS time: 0.01004 ms\n   shape (1, 5120) dtype &lt;f16&gt;\n        Torch time: 0.06121 ms\n        LLAISYS time: 0.01564 ms\n   shape (1, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.04420 ms\n        LLAISYS time: 0.01323 ms\n   shape (1024, 5120) dtype &lt;f32&gt;\n        Torch time: 0.60898 ms\n        LLAISYS time: 0.21670 ms\n   shape (1024, 5120) dtype &lt;f16&gt;\n        Torch time: 1.97151 ms\n        LLAISYS time: 0.41144 ms\n   shape (1024, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.58732 ms\n        LLAISYS time: 0.42043 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#rope","title":"RoPE","text":"Bash<pre><code>Testing Ops.rope on cpu\n   shape (1, 12, 128) range (128, 129) dtype &lt;f32&gt;\n        Torch time: 0.09013 ms\n        LLAISYS time: 0.00822 ms\n   shape (1, 12, 128) range (128, 129) dtype &lt;f16&gt;\n        Torch time: 0.10628 ms\n        LLAISYS time: 0.01259 ms\n   shape (1, 12, 128) range (128, 129) dtype &lt;bf16&gt;\n        Torch time: 0.10613 ms\n        LLAISYS time: 0.01284 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;f32&gt;\n        Torch time: 0.08892 ms\n        LLAISYS time: 0.00890 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;f16&gt;\n        Torch time: 0.10279 ms\n        LLAISYS time: 0.00797 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;bf16&gt;\n        Torch time: 0.10237 ms\n        LLAISYS time: 0.00870 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;f32&gt;\n        Torch time: 0.22165 ms\n        LLAISYS time: 0.01494 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;f16&gt;\n        Torch time: 0.28142 ms\n        LLAISYS time: 0.06918 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;bf16&gt;\n        Torch time: 0.28675 ms\n        LLAISYS time: 0.06317 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;f32&gt;\n        Torch time: 0.15358 ms\n        LLAISYS time: 0.01226 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;f16&gt;\n        Torch time: 0.17949 ms\n        LLAISYS time: 0.02157 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;bf16&gt;\n        Torch time: 0.18057 ms\n        LLAISYS time: 0.02127 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;f32&gt;\n        Torch time: 0.09240 ms\n        LLAISYS time: 0.00876 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;f16&gt;\n        Torch time: 0.11005 ms\n        LLAISYS time: 0.01904 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;bf16&gt;\n        Torch time: 0.12682 ms\n        LLAISYS time: 0.01996 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;f32&gt;\n        Torch time: 0.09114 ms\n        LLAISYS time: 0.00934 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;f16&gt;\n        Torch time: 0.10605 ms\n        LLAISYS time: 0.01183 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;bf16&gt;\n        Torch time: 0.10570 ms\n        LLAISYS time: 0.01154 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;f32&gt;\n        Torch time: 0.39850 ms\n        LLAISYS time: 0.05862 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;f16&gt;\n        Torch time: 6.75481 ms\n        LLAISYS time: 0.28545 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;bf16&gt;\n        Torch time: 6.68824 ms\n        LLAISYS time: 0.28253 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;f32&gt;\n        Torch time: 0.28273 ms\n        LLAISYS time: 0.02475 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;f16&gt;\n        Torch time: 0.32283 ms\n        LLAISYS time: 0.08710 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;bf16&gt;\n        Torch time: 0.32498 ms\n        LLAISYS time: 0.08435 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;f32&gt;\n        Torch time: 0.09264 ms\n        LLAISYS time: 0.00964 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;f16&gt;\n        Torch time: 0.10945 ms\n        LLAISYS time: 0.02222 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;bf16&gt;\n        Torch time: 0.10943 ms\n        LLAISYS time: 0.02223 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;f32&gt;\n        Torch time: 0.09015 ms\n        LLAISYS time: 0.00875 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;f16&gt;\n        Torch time: 0.10550 ms\n        LLAISYS time: 0.01039 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;bf16&gt;\n        Torch time: 0.10487 ms\n        LLAISYS time: 0.01037 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;f32&gt;\n        Torch time: 0.81286 ms\n        LLAISYS time: 0.08377 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;f16&gt;\n        Torch time: 11.78928 ms\n        LLAISYS time: 0.55016 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;bf16&gt;\n        Torch time: 11.98018 ms\n        LLAISYS time: 0.57124 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;f32&gt;\n        Torch time: 0.26156 ms\n        LLAISYS time: 0.04173 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;f16&gt;\n        Torch time: 0.32697 ms\n        LLAISYS time: 0.18694 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;bf16&gt;\n        Torch time: 0.33184 ms\n        LLAISYS time: 0.16735 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#self-attention","title":"Self-Attention","text":"Bash<pre><code>Testing Ops.self_attention on cpu\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.21772 ms\n        LLAISYS time: 0.02118 ms\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.72310 ms\n        LLAISYS time: 0.14649 ms\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.29465 ms\n        LLAISYS time: 0.13438 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.50132 ms\n        LLAISYS time: 0.35492 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f16&gt;\n        Torch time: 32.30767 ms\n        LLAISYS time: 4.52054 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.88615 ms\n        LLAISYS time: 6.39522 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 2.62542 ms\n        LLAISYS time: 0.07751 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 3.27759 ms\n        LLAISYS time: 0.73070 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.46103 ms\n        LLAISYS time: 0.65565 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 29.25550 ms\n        LLAISYS time: 10.27990 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 1214.56411 ms\n        LLAISYS time: 163.98416 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 30.98963 ms\n        LLAISYS time: 138.81445 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 1.11639 ms\n        LLAISYS time: 0.15972 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 18.02537 ms\n        LLAISYS time: 1.50406 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.70819 ms\n        LLAISYS time: 1.98549 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 107.89074 ms\n        LLAISYS time: 53.29805 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 6462.94605 ms\n        LLAISYS time: 725.99376 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 116.82543 ms\n        LLAISYS time: 620.13353 ms\nTest passed!\n</code></pre>"},{"location":"ops/cpu/#swiglu","title":"SwiGLU","text":"Bash<pre><code>Testing Ops.swiglu on cpu\n   shape (1, 8960) dtype &lt;f32&gt;\n        Torch time: 7.32909 ms\n        LLAISYS time: 0.71903 ms\n   shape (1, 8960) dtype &lt;f16&gt;\n        Torch time: 0.06433 ms\n        LLAISYS time: 0.01364 ms\n   shape (1, 8960) dtype &lt;bf16&gt;\n        Torch time: 0.06350 ms\n        LLAISYS time: 0.01543 ms\n   shape (128, 8960) dtype &lt;f32&gt;\n        Torch time: 2.15325 ms\n        LLAISYS time: 0.50715 ms\n   shape (128, 8960) dtype &lt;f16&gt;\n        Torch time: 2.22173 ms\n        LLAISYS time: 0.85925 ms\n   shape (128, 8960) dtype &lt;bf16&gt;\n        Torch time: 2.41520 ms\n        LLAISYS time: 0.79054 ms\n   shape (1, 12288) dtype &lt;f32&gt;\n        Torch time: 0.04483 ms\n        LLAISYS time: 0.01212 ms\n   shape (1, 12288) dtype &lt;f16&gt;\n        Torch time: 0.05603 ms\n        LLAISYS time: 0.01586 ms\n   shape (1, 12288) dtype &lt;bf16&gt;\n        Torch time: 0.06148 ms\n        LLAISYS time: 0.01526 ms\n   shape (512, 12288) dtype &lt;f32&gt;\n        Torch time: 15.95737 ms\n        LLAISYS time: 3.50149 ms\n   shape (512, 12288) dtype &lt;f16&gt;\n        Torch time: 10.01503 ms\n        LLAISYS time: 11.07033 ms\n   shape (512, 12288) dtype &lt;bf16&gt;\n        Torch time: 9.38210 ms\n        LLAISYS time: 6.43708 ms\n   shape (1, 27648) dtype &lt;f32&gt;\n        Torch time: 6.46970 ms\n        LLAISYS time: 0.51859 ms\n   shape (1, 27648) dtype &lt;f16&gt;\n        Torch time: 0.09058 ms\n        LLAISYS time: 0.03122 ms\n   shape (1, 27648) dtype &lt;bf16&gt;\n        Torch time: 0.10892 ms\n        LLAISYS time: 0.03298 ms\n   shape (1024, 27648) dtype &lt;f32&gt;\n        Torch time: 81.70530 ms\n        LLAISYS time: 12.51257 ms\n   shape (1024, 27648) dtype &lt;f16&gt;\n        Torch time: 64.29865 ms\n        LLAISYS time: 21.12508 ms\n   shape (1024, 27648) dtype &lt;bf16&gt;\n        Torch time: 65.57228 ms\n        LLAISYS time: 19.52978 ms\nTest passed!\n</code></pre>"},{"location":"ops/list/","title":"\u7b97\u5b50\u5217\u8868","text":"<p>\u76ee\u524d\u4ec5\u652f\u6301 <code>Float32</code>\u3001<code>Float16</code> \u548c <code>BFloat16</code> \u6570\u636e\u7c7b\u578b\u3002</p>"},{"location":"ops/list/#add","title":"Add\uff08\u52a0\u6cd5\uff09","text":"C++<pre><code>void add(tensor_t c, tensor_t a, tensor_t b);\n</code></pre> <p>\u5bf9\u5f20\u91cf <code>a</code> \u548c <code>b</code> \u6267\u884c\u9010\u5143\u7d20\u52a0\u6cd5\uff0c\u7ed3\u679c\u5b58\u5165\u5f20\u91cf <code>c</code>\u3002\u6240\u6709\u8f93\u5165\u4e0e\u8f93\u51fa\u5f20\u91cf\u5fc5\u987b\u5177\u6709\u76f8\u540c\u5f62\u72b6\u4e14\u4e3a\u8fde\u7eed\u5185\u5b58\u5e03\u5c40\u3002</p>"},{"location":"ops/list/#argmax","title":"Argmax\uff08\u53d6\u6700\u5927\u503c\u7d22\u5f15\uff09","text":"C++<pre><code>void argmax(tensor_t max_idx, tensor_t max_val, tensor_t vals);\n</code></pre> <p>\u5728 1D \u8f93\u5165\u5f20\u91cf <code>vals</code> \u4e2d\u67e5\u627e\u6700\u5927\u503c\u53ca\u5176\u5bf9\u5e94\u7d22\u5f15\u3002\u6700\u5927\u503c\u5199\u5165 <code>max_val</code>\uff0c\u5176\u7d22\u5f15\u5199\u5165 <code>max_idx</code>\u3002<code>max_val</code> \u4e0e <code>max_idx</code> \u5747\u4e3a\u5305\u542b\u5355\u4e2a\u5143\u7d20\u7684 1D \u5f20\u91cf\u3002\u8f93\u5165 <code>vals</code> \u5fc5\u987b\u662f 1D \u4e14\u8fde\u7eed\u7684\u5f20\u91cf\u3002</p>"},{"location":"ops/list/#embedding","title":"Embedding\uff08\u5d4c\u5165\u67e5\u627e\uff09","text":"C++<pre><code>void embedding(tensor_t out, tensor_t index, tensor_t weight);\n</code></pre> <p>\u6839\u636e 1D \u7684 <code>index</code> \u5411\u91cf\uff08\u6570\u636e\u7c7b\u578b\u4e3a <code>int64</code>\uff09\uff0c\u4ece 2D \u7684 <code>weight</code> \u77e9\u9635\u4e2d\u6309\u884c\u7d22\u5f15\u53d6\u51fa\u5bf9\u5e94\u884c\uff0c\u7ed3\u679c\u5199\u5165 2D \u8f93\u51fa\u5f20\u91cf <code>out</code>\u3002<code>weight</code> \u5fc5\u987b\u662f 2D \u8fde\u7eed\u5f20\u91cf\uff0c<code>index</code> \u5fc5\u987b\u662f 1D \u7684 <code>int64</code> \u5f20\u91cf\u3002</p>"},{"location":"ops/list/#linear","title":"Linear\uff08\u7ebf\u6027\u53d8\u6362\uff09","text":"C++<pre><code>void linear(tensor_t out, tensor_t in, tensor_t weight, tensor_t bias);\n</code></pre> \\[ Y = XW^T + b \\] <p>\u8ba1\u7b97\u7ebf\u6027\u53d8\u6362 \\(Y = XW^T + b\\)\uff0c\u5176\u4e2d\uff1a</p> <ul> <li><code>in</code> \u5373 \\(X\\)\uff0c\u4e3a 2D \u8fde\u7eed\u8f93\u5165\u5f20\u91cf\uff1b</li> <li><code>weight</code> \u5373 \\(W\\)\uff0c\u4e3a 2D \u8fde\u7eed\u6743\u91cd\u5f20\u91cf\uff08\u65e0\u9700\u9884\u5148\u8f6c\u7f6e\uff09\uff1b</li> <li><code>bias</code> \u5373 \\(b\\)\uff0c\u4e3a\u53ef\u9009\u7684 1D \u504f\u7f6e\u5f20\u91cf\uff08\u82e5\u672a\u63d0\u4f9b\uff0c\u5219\u4e0d\u52a0\u504f\u7f6e\uff09\uff1b</li> <li><code>out</code> \u5373 \\(Y\\)\uff0c\u4e3a 2D \u8fde\u7eed\u8f93\u51fa\u5f20\u91cf\u3002</li> </ul>"},{"location":"ops/list/#rms-normalization","title":"RMS Normalization\uff08\u5747\u65b9\u6839\u5f52\u4e00\u5316\uff09","text":"C++<pre><code>void rms_norm(tensor_t out, tensor_t in, tensor_t weight, float eps);\n</code></pre> <p>\u5bf9\u8f93\u5165\u5f20\u91cf <code>in</code> \u7684\u6bcf\u4e00\u884c\u6cbf\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u8fdb\u884c RMS \u5f52\u4e00\u5316\uff0c\u516c\u5f0f\u4e3a\uff1a</p> \\[ Y_i = \\frac{W \\odot  X_i}{\\sqrt{\\frac{1}{d} \\sum_{j=1}^d X_{i,j}^2 + \\varepsilon}} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li><code>in</code> \u5373 \\(X\\)\uff0c\u4e3a 2D \u8fde\u7eed\u8f93\u5165\u5f20\u91cf\uff1b</li> <li><code>weight</code> \u5373 \\(W\\)\uff0c\u4e3a\u957f\u5ea6\u7b49\u4e8e\u8f93\u5165\u884c\u5bbd \\(d\\) \u7684 1D \u6743\u91cd\u5f20\u91cf\uff1b</li> <li><code>eps</code> \u5373 \\(\\varepsilon\\)\uff0c\u4e3a\u9632\u6b62\u9664\u96f6\u7684\u5c0f\u5e38\u6570\uff1b</li> <li><code>out</code> \u5373 \\(Y\\)\uff0c\u4e3a 2D \u8fde\u7eed\u8f93\u51fa\u5f20\u91cf\u3002</li> </ul>"},{"location":"ops/list/#rope","title":"RoPE\uff08\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\uff09","text":"<p>C++<pre><code>void rope(tensor_t out, tensor_t in, tensor_t pos_ids, float theta);\n</code></pre> \u4e3a\u8f93\u5165\u5f20\u91cf<code>in</code>\u7684\u6bcf\u4e2a\u5411\u91cf\uff08\u8fd9\u4e9b\u5411\u91cf\u4e0e pos_ids \u4e2d\u7684\u4f4d\u7f6e id \u76f8\u5bf9\u5e94\uff09\u8ba1\u7b97\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <p>\u8bbe \\(\\mathbf{x}_i = [\\mathbf{a}_i, \\mathbf{b}_i] \\in \\mathbb{R}^d\\) \u4e3a\u8f93\u5165\u5411\u91cf\uff0c \\(\\mathbf{y}_i = [\\mathbf{a}'_i, \\mathbf{b}'_i] \\in \\mathbb{R}^d\\) \u4e3a\u7d22\u5f15 \\(i\\) \u5904\u7684\u8f93\u51fa\u5411\u91cf\uff0c\u5176\u4e2d \\(\\mathbf{a}_i, \\mathbf{b}_i,\\mathbf{a}'_i, \\mathbf{b}'_i \\in \\mathbb{R}^{d/2}\\) \u3002</p> <p>\u8bbe \\(\\theta\\) \u4e3a\u56fa\u5b9a\u57fa\u6570\uff08\u4f8b\u5982 \\(\\theta = 10000\\)\uff09\uff0c \\(j = 0, 1, \\ldots, d/2 - 1\\)\u3002</p> <p>\u8bbe \\(p_i \\in \\mathbb{N}\\) \u662f\u8f93\u5165\u7d22\u5f15 \\(i\\) \u5904token\u7684\u4f4d\u7f6eid\u3002</p> <p>\u90a3\u4e48RoPE\u7684\u89d2\u5ea6\u4e3a \\(\\phi_{i,j} = \\frac{p_i}{\\theta^{2j/d}}\\)</p> <p>\u8f93\u51fa\u5411\u91cf \\(\\mathbf{y}_i = [\\mathbf{a}'_i, \\mathbf{b}'_i]\\) \u8ba1\u7b97\u5982\u4e0b\uff1a</p> \\[a_{i,j}' = a_{i,j} \\cos(\\phi_{i,j}) - b_{i,j} \\sin(\\phi_{i,j})\\] \\[b_{i,j}' = b_{i,j} \\cos(\\phi_{i,j}) + a_{i,j} \\sin(\\phi_{i,j})\\] <ul> <li><code>out</code>\uff1a\u7f16\u7801\u540e\u7684\u67e5\u8be2\uff08Q\uff09\u6216\u952e\uff08K\uff09\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[seqlen, nhead, d]</code> \u6216 <code>[seqlen, nkvhead, d]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>in</code>\uff1a\u539f\u59cb\u67e5\u8be2\uff08Q\uff09\u6216\u952e\uff08K\uff09\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[seqlen, nhead, d]</code> \u6216 <code>[seqlen, nkvhead, d]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>pos_ids</code>\uff1a\u8f93\u5165\u5e8f\u5217\u4e2d\u6bcf\u4e2atoken\u7684\u4f4d\u7f6eid\uff08\u6574\u4e2a\u4e0a\u4e0b\u6587\u4e2d\u7684\u7d22\u5f15\uff09\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[seqlen,]</code>\uff0cdtype\u5e94\u8be5\u662f<code>int64</code>\u3002</li> <li><code>theta</code>\uff1a\u9891\u7387\u5411\u91cf\u7684\u57fa\u503c\uff08\u5982 10000\uff09\u3002</li> </ul>"},{"location":"ops/list/#self-attention","title":"Self-Attention\uff08\u81ea\u6ce8\u610f\u529b\uff09","text":"<p>C++<pre><code>void self_attention(tensor_t attn_val, tensor_t q, tensor_t k, tensor_t v, float scale);\n</code></pre> \u4e3a\u67e5\u8be2\u5f20\u91cf<code>q</code>\u3001\u952e\u5f20\u91cf<code>k</code>\u548c\u503c\u5f20\u91cf<code>v</code>\u8ba1\u7b97\u5e26\u56e0\u679c\u63a9\u7801\u7684\u81ea\u6ce8\u610f\u529b\u3002</p> \\[ A = Q K^\\top * scale \\\\ \\] \\[ Y = \\mathrm{causalsoftmax}(A) \\cdot V \\\\ \\] <ul> <li><code>attn_val</code>\uff1a\u7ed3\u679c\u6ce8\u610f\u529b\u503c\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f<code>[seqlen, nhead, dv]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>q</code>\uff1a\u67e5\u8be2\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[seqlen, nhead, d]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>k</code>\uff1a\u952e\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[total_len, nkvhead, d]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>v</code>\uff1a\u503c\u5f20\u91cf\u3002\u5f62\u72b6\u5e94\u8be5\u662f <code>[total_len, nkvhead, dv]</code>\u3002\u6682\u65f6\u53ef\u4ee5\u5047\u8bbe\u5f20\u91cf\u662f\u8fde\u7eed\u7684\u3002</li> <li><code>scale</code>\uff1a\u7f29\u653e\u56e0\u5b50\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u53d6\u503c\u4e3a \\(\\frac{1}{\\sqrt{d}}\\) \u3002</li> </ul> <p><code>total_len</code> = <code>past_len</code> + <code>seq_len</code>\uff0c\u8ba1\u7b97\u5f53\u524d\u6279\u6b21<code>seq_len</code>\u4e2atoken\u7684attention\u65f6\uff0c\u9700\u8981\u6ce8\u610f\u5230\u524d\u9762\u7684<code>past_len</code>\u4e2atoken\u4ee5\u53ca\u5f53\u524d\u6279\u6b21\u7684<code>1..seq_len</code>\u4e2atoken\u7684\u952e\uff08K\uff09,\u6b64\u5904\u9700\u8981\u6ce8\u610f kvcache \u7684\u62fc\u63a5\u3002</p>"},{"location":"ops/list/#swigluswish-gated-linear-unit","title":"SwiGLU\uff08Swish-Gated Linear Unit\uff09","text":"C++<pre><code>void swiglu(tensor_t out, tensor_t gate, tensor_t up);\n</code></pre> <p>\u8ba1\u7b97 SwiGLU \u6fc0\u6d3b\u51fd\u6570\uff1a</p> \\[ out_{i} = up_{i} \\odot \\frac { gate_{i}}{1 + e^{-gate_{i}}} \\] <p>\\(e^{\u2212gate_i}\\) \u8868\u793a\u5bf9 \\(gate_i\\) \u5411\u91cf\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5355\u72ec\u8fdb\u884c\u6307\u6570\u8fd0\u7b97\u3002</p> <p>\u5176\u4e2d <code>gate</code>\u3001<code>up</code> \u548c <code>out</code> \u5747\u4e3a\u5f62\u72b6\u76f8\u540c\u7684 2D \u8fde\u7eed\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a <code>[seqlen, intermediate_size]</code>\u3002</p>"},{"location":"ops/list/#rearrange","title":"Rearrange\uff08\u91cd\u6392\uff09","text":"C++<pre><code>void rearrange(tensor_t out, tensor_t in);\n</code></pre> <p>\u5c06\u6570\u636e\u4ece\u8f93\u5165\u5f20\u91cf <code>in</code> \u590d\u5236\u5230\u8f93\u51fa\u5f20\u91cf <code>out</code>\uff0c\u4e24\u8005\u5177\u6709\u76f8\u540c\u903b\u8f91\u5f62\u72b6\u4f46\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u5185\u5b58\u6b65\u957f\uff08strides\uff09\u3002\u8be5\u7b97\u5b50\u53ef\u7528\u4e8e\u5b9e\u73b0\u5f20\u91cf\u7684 <code>contiguous()</code> \u529f\u80fd\uff0c\u786e\u4fdd\u8f93\u51fa\u4e3a\u8fde\u7eed\u5185\u5b58\u5e03\u5c40\u3002</p>"},{"location":"ops/nvidia/","title":"NVIDIA \u7b97\u5b50\u6027\u80fd\u6d4b\u8bc4","text":""},{"location":"ops/nvidia/#add","title":"Add","text":"Bash<pre><code>Testing Ops.add on nvidia\n   shape (1, 1536) dtype &lt;f32&gt;\n        Torch time: 0.00601 ms\n        LLAISYS time: 0.00451 ms\n   shape (1, 1536) dtype &lt;f16&gt;\n        Torch time: 0.00660 ms\n        LLAISYS time: 0.00407 ms\n   shape (1, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.00613 ms\n        LLAISYS time: 0.00407 ms\n   shape (128, 1536) dtype &lt;f32&gt;\n        Torch time: 0.00610 ms\n        LLAISYS time: 0.00447 ms\n   shape (128, 1536) dtype &lt;f16&gt;\n        Torch time: 0.00635 ms\n        LLAISYS time: 0.00435 ms\n   shape (128, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.00632 ms\n        LLAISYS time: 0.00407 ms\n   shape (1, 4096) dtype &lt;f32&gt;\n        Torch time: 0.00638 ms\n        LLAISYS time: 0.00405 ms\n   shape (1, 4096) dtype &lt;f16&gt;\n        Torch time: 0.00594 ms\n        LLAISYS time: 0.00441 ms\n   shape (1, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.00633 ms\n        LLAISYS time: 0.00437 ms\n   shape (512, 4096) dtype &lt;f32&gt;\n        Torch time: 0.00735 ms\n        LLAISYS time: 0.00684 ms\n   shape (512, 4096) dtype &lt;f16&gt;\n        Torch time: 0.00636 ms\n        LLAISYS time: 0.00448 ms\n   shape (512, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.00604 ms\n        LLAISYS time: 0.00477 ms\n   shape (1, 5120) dtype &lt;f32&gt;\n        Torch time: 0.00605 ms\n        LLAISYS time: 0.00443 ms\n   shape (1, 5120) dtype &lt;f16&gt;\n        Torch time: 0.00654 ms\n        LLAISYS time: 0.00446 ms\n   shape (1, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.00617 ms\n        LLAISYS time: 0.00403 ms\n   shape (1024, 5120) dtype &lt;f32&gt;\n        Torch time: 0.01521 ms\n        LLAISYS time: 0.01394 ms\n   shape (1024, 5120) dtype &lt;f16&gt;\n        Torch time: 0.00787 ms\n        LLAISYS time: 0.00798 ms\n   shape (1024, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.00784 ms\n        LLAISYS time: 0.00803 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#argmax","title":"Argmax","text":"Bash<pre><code>Testing Ops.argmax on nvidia\n   shape (151936,) dtype &lt;f32&gt;\n        Torch time: 0.01250 ms\n        LLAISYS time: 0.01077 ms\n   shape (151936,) dtype &lt;f16&gt;\n        Torch time: 0.01247 ms\n        LLAISYS time: 0.01061 ms\n   shape (151936,) dtype &lt;bf16&gt;\n        Torch time: 0.01216 ms\n        LLAISYS time: 0.01066 ms\n   shape (152064,) dtype &lt;f32&gt;\n        Torch time: 0.01263 ms\n        LLAISYS time: 0.01072 ms\n   shape (152064,) dtype &lt;f16&gt;\n        Torch time: 0.01235 ms\n        LLAISYS time: 0.01047 ms\n   shape (152064,) dtype &lt;bf16&gt;\n        Torch time: 0.01221 ms\n        LLAISYS time: 0.01080 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#embedding","title":"Embedding","text":"Bash<pre><code>Testing Ops.embedding on nvidia\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;f32&gt;\n        Torch time: 0.02439 ms\n        LLAISYS time: 0.00401 ms\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;f16&gt;\n        Torch time: 0.02388 ms\n        LLAISYS time: 0.00395 ms\n   idx_shape (1,) embd_shape (151936, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.02367 ms\n        LLAISYS time: 0.00400 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;f32&gt;\n        Torch time: 0.02372 ms\n        LLAISYS time: 0.00390 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;f16&gt;\n        Torch time: 0.02389 ms\n        LLAISYS time: 0.00396 ms\n   idx_shape (128,) embd_shape (151936, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.02406 ms\n        LLAISYS time: 0.00394 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;f32&gt;\n        Torch time: 0.02390 ms\n        LLAISYS time: 0.00390 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;f16&gt;\n        Torch time: 0.02368 ms\n        LLAISYS time: 0.00389 ms\n   idx_shape (1,) embd_shape (151936, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.03043 ms\n        LLAISYS time: 0.00596 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;f32&gt;\n        Torch time: 0.03046 ms\n        LLAISYS time: 0.00601 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;f16&gt;\n        Torch time: 0.03191 ms\n        LLAISYS time: 0.00611 ms\n   idx_shape (512,) embd_shape (151936, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.03066 ms\n        LLAISYS time: 0.00609 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;f32&gt;\n        Torch time: 0.03077 ms\n        LLAISYS time: 0.00605 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;f16&gt;\n        Torch time: 0.03210 ms\n        LLAISYS time: 0.00593 ms\n   idx_shape (1,) embd_shape (152064, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.03061 ms\n        LLAISYS time: 0.00590 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;f32&gt;\n        Torch time: 0.03076 ms\n        LLAISYS time: 0.01198 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;f16&gt;\n        Torch time: 0.03053 ms\n        LLAISYS time: 0.00659 ms\n   idx_shape (1024,) embd_shape (152064, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.03052 ms\n        LLAISYS time: 0.00656 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#linear","title":"Linear","text":"Bash<pre><code>Testing Ops.linear on nvidia\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.01348 ms\n        LLAISYS time: 0.00514 ms\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.01355 ms\n        LLAISYS time: 0.00494 ms\n   out (1, 1536), x (1, 1536), w (1536, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.01335 ms\n        LLAISYS time: 0.00497 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.01721 ms\n        LLAISYS time: 0.01516 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.01417 ms\n        LLAISYS time: 0.01058 ms\n   out (1, 8960), x (1, 1536), w (8960, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.01407 ms\n        LLAISYS time: 0.01063 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;f32&gt;\n        Torch time: 0.06036 ms\n        LLAISYS time: 0.01616 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;f16&gt;\n        Torch time: 0.02144 ms\n        LLAISYS time: 0.00953 ms\n   out (1, 1536), x (1, 8960), w (1536, 8960), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.02142 ms\n        LLAISYS time: 0.00938 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.02972 ms\n        LLAISYS time: 0.12685 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.01788 ms\n        LLAISYS time: 0.10841 ms\n   out (128, 1536), x (128, 1536), w (1536, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.01815 ms\n        LLAISYS time: 0.12291 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;f32&gt;\n        Torch time: 0.11554 ms\n        LLAISYS time: 0.12955 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;f16&gt;\n        Torch time: 0.03631 ms\n        LLAISYS time: 0.11285 ms\n   out (128, 8960), x (128, 1536), w (8960, 1536), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.03560 ms\n        LLAISYS time: 0.11753 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;f32&gt;\n        Torch time: 0.14444 ms\n        LLAISYS time: 0.64426 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;f16&gt;\n        Torch time: 0.03368 ms\n        LLAISYS time: 0.54038 ms\n   out (128, 1536), x (128, 8960), w (1536, 8960), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.03427 ms\n        LLAISYS time: 0.62360 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 0.01778 ms\n        LLAISYS time: 0.01610 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 0.01648 ms\n        LLAISYS time: 0.00998 ms\n   out (1, 4096), x (1, 4096), w (4096, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.01656 ms\n        LLAISYS time: 0.00974 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 0.21247 ms\n        LLAISYS time: 0.21262 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 0.12607 ms\n        LLAISYS time: 0.10752 ms\n   out (1, 12288), x (1, 4096), w (12288, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.10765 ms\n        LLAISYS time: 0.10747 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;f32&gt;\n        Torch time: 0.24006 ms\n        LLAISYS time: 0.21333 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;f16&gt;\n        Torch time: 0.11025 ms\n        LLAISYS time: 0.10743 ms\n   out (1, 4096), x (1, 12288), w (4096, 12288), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.10960 ms\n        LLAISYS time: 0.10746 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 0.51945 ms\n        LLAISYS time: 0.55372 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 0.14940 ms\n        LLAISYS time: 0.30586 ms\n   out (512, 4096), x (512, 4096), w (4096, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.12349 ms\n        LLAISYS time: 0.28948 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;f32&gt;\n        Torch time: 1.49008 ms\n        LLAISYS time: 2.18085 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;f16&gt;\n        Torch time: 0.38936 ms\n        LLAISYS time: 0.62070 ms\n   out (512, 12288), x (512, 4096), w (12288, 4096), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.37691 ms\n        LLAISYS time: 0.67241 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;f32&gt;\n        Torch time: 1.31109 ms\n        LLAISYS time: 1.58544 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;f16&gt;\n        Torch time: 0.37869 ms\n        LLAISYS time: 0.83337 ms\n   out (512, 4096), x (512, 12288), w (4096, 12288), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.39339 ms\n        LLAISYS time: 0.96134 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 0.11283 ms\n        LLAISYS time: 0.11176 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 0.05745 ms\n        LLAISYS time: 0.01466 ms\n   out (1, 5120), x (1, 5120), w (5120, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.05745 ms\n        LLAISYS time: 0.01442 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 0.59248 ms\n        LLAISYS time: 0.59327 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 0.30158 ms\n        LLAISYS time: 0.29777 ms\n   out (1, 27648), x (1, 5120), w (27648, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.29766 ms\n        LLAISYS time: 0.29775 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;f32&gt;\n        Torch time: 0.65929 ms\n        LLAISYS time: 0.59280 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;f16&gt;\n        Torch time: 0.30365 ms\n        LLAISYS time: 0.29755 ms\n   out (1, 5120), x (1, 27648), w (5120, 27648), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.30002 ms\n        LLAISYS time: 0.29766 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 1.49345 ms\n        LLAISYS time: 1.81029 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 0.36449 ms\n        LLAISYS time: 0.67310 ms\n   out (1024, 5120), x (1024, 5120), w (5120, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 0.37387 ms\n        LLAISYS time: 0.75395 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;f32&gt;\n        Torch time: 8.68043 ms\n        LLAISYS time: 19.29609 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;f16&gt;\n        Torch time: 1.98788 ms\n        LLAISYS time: 4.22887 ms\n   out (1024, 27648), x (1024, 5120), w (27648, 5120), bias True, dtype &lt;bf16&gt;\n        Torch time: 1.91801 ms\n        LLAISYS time: 4.30433 ms\n   out (1024, 5120), x (1024, 27648), w (5120, 27648), bias True, dtype &lt;f32&gt;\n        Torch time: 7.54219 ms\n        LLAISYS time: 11.05026 ms\n   out (1024, 5120), x (1024, 27648), w (5120, 27648), bias True, dtype &lt;f16&gt;\n        Torch time: 1.96672 ms\n        LLAISYS time: 3.85739 ms\n   out (1024, 5120), x (1024, 27648), w (5120, 27648), bias True, dtype &lt;bf16&gt;\n        Torch time: 1.92490 ms\n        LLAISYS time: 4.12456 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#rms-norm","title":"RMS Norm","text":"Bash<pre><code>Testing Ops.rms_norm on nvidia\n   shape (1, 1536) dtype &lt;f32&gt;\n        Torch time: 0.04422 ms\n        LLAISYS time: 0.00435 ms\n   shape (1, 1536) dtype &lt;f16&gt;\n        Torch time: 0.04477 ms\n        LLAISYS time: 0.00451 ms\n   shape (1, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.04448 ms\n        LLAISYS time: 0.00437 ms\n   shape (128, 1536) dtype &lt;f32&gt;\n        Torch time: 0.04466 ms\n        LLAISYS time: 0.00444 ms\n   shape (128, 1536) dtype &lt;f16&gt;\n        Torch time: 0.04488 ms\n        LLAISYS time: 0.00440 ms\n   shape (128, 1536) dtype &lt;bf16&gt;\n        Torch time: 0.04485 ms\n        LLAISYS time: 0.00440 ms\n   shape (1, 4096) dtype &lt;f32&gt;\n        Torch time: 0.04429 ms\n        LLAISYS time: 0.00435 ms\n   shape (1, 4096) dtype &lt;f16&gt;\n        Torch time: 0.04460 ms\n        LLAISYS time: 0.00444 ms\n   shape (1, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.04481 ms\n        LLAISYS time: 0.00435 ms\n   shape (512, 4096) dtype &lt;f32&gt;\n        Torch time: 0.04508 ms\n        LLAISYS time: 0.00736 ms\n   shape (512, 4096) dtype &lt;f16&gt;\n        Torch time: 0.04529 ms\n        LLAISYS time: 0.00458 ms\n   shape (512, 4096) dtype &lt;bf16&gt;\n        Torch time: 0.04517 ms\n        LLAISYS time: 0.00449 ms\n   shape (1, 5120) dtype &lt;f32&gt;\n        Torch time: 0.04412 ms\n        LLAISYS time: 0.00438 ms\n   shape (1, 5120) dtype &lt;f16&gt;\n        Torch time: 0.04475 ms\n        LLAISYS time: 0.00447 ms\n   shape (1, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.04469 ms\n        LLAISYS time: 0.00439 ms\n   shape (1024, 5120) dtype &lt;f32&gt;\n        Torch time: 0.05101 ms\n        LLAISYS time: 0.01690 ms\n   shape (1024, 5120) dtype &lt;f16&gt;\n        Torch time: 0.04646 ms\n        LLAISYS time: 0.00891 ms\n   shape (1024, 5120) dtype &lt;bf16&gt;\n        Torch time: 0.04534 ms\n        LLAISYS time: 0.00885 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#rope","title":"RoPE","text":"Bash<pre><code>Testing Ops.rope on nvidia\n   shape (1, 12, 128) range (128, 129) dtype &lt;f32&gt;\n        Torch time: 0.18430 ms\n        LLAISYS time: 0.00432 ms\n   shape (1, 12, 128) range (128, 129) dtype &lt;f16&gt;\n        Torch time: 0.18480 ms\n        LLAISYS time: 0.00430 ms\n   shape (1, 12, 128) range (128, 129) dtype &lt;bf16&gt;\n        Torch time: 0.18376 ms\n        LLAISYS time: 0.00445 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;f32&gt;\n        Torch time: 0.18296 ms\n        LLAISYS time: 0.00433 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;f16&gt;\n        Torch time: 0.18336 ms\n        LLAISYS time: 0.00434 ms\n   shape (1, 2, 128) range (128, 129) dtype &lt;bf16&gt;\n        Torch time: 0.18369 ms\n        LLAISYS time: 0.00432 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;f32&gt;\n        Torch time: 0.18474 ms\n        LLAISYS time: 0.00427 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;f16&gt;\n        Torch time: 0.18552 ms\n        LLAISYS time: 0.00427 ms\n   shape (128, 12, 128) range (0, 128) dtype &lt;bf16&gt;\n        Torch time: 0.18537 ms\n        LLAISYS time: 0.00436 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;f32&gt;\n        Torch time: 0.18454 ms\n        LLAISYS time: 0.00441 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;f16&gt;\n        Torch time: 0.18626 ms\n        LLAISYS time: 0.00429 ms\n   shape (128, 2, 128) range (0, 128) dtype &lt;bf16&gt;\n        Torch time: 0.18570 ms\n        LLAISYS time: 0.00432 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;f32&gt;\n        Torch time: 0.18336 ms\n        LLAISYS time: 0.00434 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;f16&gt;\n        Torch time: 0.18426 ms\n        LLAISYS time: 0.00425 ms\n   shape (1, 32, 128) range (512, 513) dtype &lt;bf16&gt;\n        Torch time: 0.18399 ms\n        LLAISYS time: 0.00435 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;f32&gt;\n        Torch time: 0.18283 ms\n        LLAISYS time: 0.00433 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;f16&gt;\n        Torch time: 0.18466 ms\n        LLAISYS time: 0.00439 ms\n   shape (1, 8, 128) range (512, 513) dtype &lt;bf16&gt;\n        Torch time: 0.18529 ms\n        LLAISYS time: 0.00430 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;f32&gt;\n        Torch time: 0.18410 ms\n        LLAISYS time: 0.01078 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;f16&gt;\n        Torch time: 0.18524 ms\n        LLAISYS time: 0.01091 ms\n   shape (512, 32, 128) range (0, 512) dtype &lt;bf16&gt;\n        Torch time: 0.18621 ms\n        LLAISYS time: 0.01093 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;f32&gt;\n        Torch time: 0.18407 ms\n        LLAISYS time: 0.00441 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;f16&gt;\n        Torch time: 0.18584 ms\n        LLAISYS time: 0.00432 ms\n   shape (512, 8, 128) range (0, 512) dtype &lt;bf16&gt;\n        Torch time: 0.18505 ms\n        LLAISYS time: 0.00439 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;f32&gt;\n        Torch time: 0.18422 ms\n        LLAISYS time: 0.00426 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;f16&gt;\n        Torch time: 0.18528 ms\n        LLAISYS time: 0.00427 ms\n   shape (1, 40, 128) range (1024, 1025) dtype &lt;bf16&gt;\n        Torch time: 0.18453 ms\n        LLAISYS time: 0.00441 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;f32&gt;\n        Torch time: 0.18349 ms\n        LLAISYS time: 0.00431 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;f16&gt;\n        Torch time: 0.18466 ms\n        LLAISYS time: 0.00432 ms\n   shape (1, 8, 128) range (1024, 1025) dtype &lt;bf16&gt;\n        Torch time: 0.18458 ms\n        LLAISYS time: 0.00442 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;f32&gt;\n        Torch time: 0.18489 ms\n        LLAISYS time: 0.01979 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;f16&gt;\n        Torch time: 0.18714 ms\n        LLAISYS time: 0.01998 ms\n   shape (1024, 32, 128) range (0, 1024) dtype &lt;bf16&gt;\n        Torch time: 0.18619 ms\n        LLAISYS time: 0.01993 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;f32&gt;\n        Torch time: 0.18551 ms\n        LLAISYS time: 0.00634 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;f16&gt;\n        Torch time: 0.18614 ms\n        LLAISYS time: 0.00632 ms\n   shape (1024, 8, 128) range (0, 1024) dtype &lt;bf16&gt;\n        Torch time: 0.18625 ms\n        LLAISYS time: 0.00631 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#self-attention","title":"Self-Attention","text":"Bash<pre><code>Testing Ops.self_attention on nvidia\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.20475 ms\n        LLAISYS time: 0.01203 ms\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.21212 ms\n        LLAISYS time: 0.01208 ms\n   qlen=1 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.21083 ms\n        LLAISYS time: 0.01208 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.20639 ms\n        LLAISYS time: 0.02627 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.21229 ms\n        LLAISYS time: 0.02829 ms\n   qlen=128 kvlen=128 nh=12 nkvh=2 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.22925 ms\n        LLAISYS time: 0.02871 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.21123 ms\n        LLAISYS time: 0.04198 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.21233 ms\n        LLAISYS time: 0.04233 ms\n   qlen=1 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.20979 ms\n        LLAISYS time: 0.04233 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.27158 ms\n        LLAISYS time: 0.83619 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.21210 ms\n        LLAISYS time: 0.82933 ms\n   qlen=512 kvlen=512 nh=32 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.20683 ms\n        LLAISYS time: 0.81187 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 0.21107 ms\n        LLAISYS time: 0.08164 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.21887 ms\n        LLAISYS time: 0.07632 ms\n   qlen=1 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.27532 ms\n        LLAISYS time: 0.07499 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f32&gt;\n        Torch time: 1.83715 ms\n        LLAISYS time: 4.12091 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;f16&gt;\n        Torch time: 0.87240 ms\n        LLAISYS time: 4.44587 ms\n   qlen=1024 kvlen=1024 nh=40 nkvh=8 hd=128 dtype &lt;bf16&gt;\n        Torch time: 0.87514 ms\n        LLAISYS time: 4.03622 ms\nTest passed!\n</code></pre>"},{"location":"ops/nvidia/#swiglu","title":"SwiGLU","text":"Bash<pre><code>Testing Ops.swiglu on nvidia\n   shape (1, 8960) dtype &lt;f32&gt;\n        Torch time: 0.04037 ms\n        LLAISYS time: 0.00391 ms\n   shape (1, 8960) dtype &lt;f16&gt;\n        Torch time: 0.05835 ms\n        LLAISYS time: 0.00400 ms\n   shape (1, 8960) dtype &lt;bf16&gt;\n        Torch time: 0.05849 ms\n        LLAISYS time: 0.00397 ms\n   shape (128, 8960) dtype &lt;f32&gt;\n        Torch time: 0.04098 ms\n        LLAISYS time: 0.00480 ms\n   shape (128, 8960) dtype &lt;f16&gt;\n        Torch time: 0.05893 ms\n        LLAISYS time: 0.00388 ms\n   shape (128, 8960) dtype &lt;bf16&gt;\n        Torch time: 0.05868 ms\n        LLAISYS time: 0.00404 ms\n   shape (1, 12288) dtype &lt;f32&gt;\n        Torch time: 0.04001 ms\n        LLAISYS time: 0.00395 ms\n   shape (1, 12288) dtype &lt;f16&gt;\n        Torch time: 0.05830 ms\n        LLAISYS time: 0.00390 ms\n   shape (1, 12288) dtype &lt;bf16&gt;\n        Torch time: 0.05806 ms\n        LLAISYS time: 0.00393 ms\n   shape (512, 12288) dtype &lt;f32&gt;\n        Torch time: 0.15680 ms\n        LLAISYS time: 0.02872 ms\n   shape (512, 12288) dtype &lt;f16&gt;\n        Torch time: 0.10040 ms\n        LLAISYS time: 0.00955 ms\n   shape (512, 12288) dtype &lt;bf16&gt;\n        Torch time: 0.10050 ms\n        LLAISYS time: 0.00963 ms\n   shape (1, 27648) dtype &lt;f32&gt;\n        Torch time: 0.04011 ms\n        LLAISYS time: 0.00386 ms\n   shape (1, 27648) dtype &lt;f16&gt;\n        Torch time: 0.05859 ms\n        LLAISYS time: 0.00387 ms\n   shape (1, 27648) dtype &lt;bf16&gt;\n        Torch time: 0.05822 ms\n        LLAISYS time: 0.00391 ms\n   shape (1024, 27648) dtype &lt;f32&gt;\n        Torch time: 1.47460 ms\n        LLAISYS time: 0.36575 ms\n   shape (1024, 27648) dtype &lt;f16&gt;\n        Torch time: 1.33505 ms\n        LLAISYS time: 0.18278 ms\n   shape (1024, 27648) dtype &lt;bf16&gt;\n        Torch time: 1.33486 ms\n        LLAISYS time: 0.18311 ms\nTest passed!\n</code></pre>"}]}